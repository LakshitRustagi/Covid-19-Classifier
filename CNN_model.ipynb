{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from keras_preprocessing import image\r\n",
    "import tensorflow as tf"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "metadata": {
    "id": "SHSw4jE1yBJZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\r\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_datagenerator = image.ImageDataGenerator(\r\n",
    "    rotation_range = 0.18,\r\n",
    "    shear_range = 0.18,\r\n",
    "    zoom_range  = 0.18,\r\n",
    "    fill_mode='reflect',\r\n",
    "    rescale=1./255,\r\n",
    "    horizontal_flip=True\r\n",
    ")\r\n",
    "\r\n",
    "validation_datagenerator = image.ImageDataGenerator(\r\n",
    "    rescale=1./255\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "id": "EBrgkKuYqT-Y"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train = train_datagenerator.flow_from_directory(\r\n",
    "    \"Datasets/Train\",\r\n",
    "    target_size= (224,224),\r\n",
    "    batch_size=32,\r\n",
    "    # color_mode='grayscale',\r\n",
    "    class_mode = \"binary\"\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 6000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_RtgCCEy2Yx",
    "outputId": "d5e61a47-4fa6-4fd9-dadb-7f0f959a35a9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train.class_indices"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'covid': 0, 'normal': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuVN4WfYy-nQ",
    "outputId": "179e477a-cf3d-45b1-99a2-84e5814280d1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "test = validation_datagenerator.flow_from_directory(\r\n",
    "    \"Datasets/Validation\",\r\n",
    "    target_size=(224,224),\r\n",
    "    batch_size=30,\r\n",
    "    class_mode='binary'\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1232 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVd57m4Hza4O",
    "outputId": "e2396980-0ca0-4442-c69c-223f2c8dad13"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "test.class_indices"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'covid': 0, 'normal': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3FBjIPNj4swV",
    "outputId": "bd09423b-22b2-4227-9278-d75c567d8fca"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MODEL\r\n"
   ],
   "metadata": {
    "id": "HPQJ9LJS41Z3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from keras.models import Sequential\r\n",
    "from keras.layers import Conv2D,Dense,MaxPool2D,Dropout,Flatten,BatchNormalization"
   ],
   "outputs": [],
   "metadata": {
    "id": "ax9fQI984xTk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def create_model():\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(224,224,3)))  \r\n",
    "    model.add(MaxPool2D())\r\n",
    "\r\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))  \r\n",
    "    model.add(MaxPool2D())\r\n",
    "\r\n",
    "    model.add(Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\r\n",
    "    model.add(MaxPool2D())\r\n",
    "\r\n",
    "    model.add(Conv2D(filters=256,kernel_size=(3,3),activation='relu'))\r\n",
    "    model.add(MaxPool2D())\r\n",
    "\r\n",
    "    model.add(Conv2D(filters=256,kernel_size=(3,3),activation='relu'))\r\n",
    "    model.add(MaxPool2D())\r\n",
    "\r\n",
    "    model.add(Flatten())\r\n",
    "    model.add(Dense(512,activation='relu'))\r\n",
    "    model.add(Dropout(0.2))\r\n",
    "    model.add(Dense(1,activation='sigmoid'))\r\n",
    "\r\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\r\n",
    "    print(model.summary())\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "ePWcRC1g5c7e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import os\r\n",
    "import keras\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "FW604gRqXFhQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\r\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,CSVLogger\r\n",
    "filepath = \"Datasets/best_model.hdf5\"\r\n",
    "checkpoint = ModelCheckpoint(filepath,monitor='val_accuracy',verbose=1,save_best_only=True,mode = \"max\")\r\n",
    "\r\n",
    "early_stopping = EarlyStopping(monitor='val_loss',verbose=1,patience=3)\r\n",
    "\r\n",
    "log_csv = CSVLogger('Datasets/model_logs.csv',separator=',',append=False)\r\n",
    "\r\n",
    "callback_list = [checkpoint,early_stopping,log_csv]"
   ],
   "outputs": [],
   "metadata": {
    "id": "Uh-WF1qXQzOH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "if os.path.exists(filepath):\r\n",
    "    model = keras.models.load_model(filepath)\r\n",
    "else :\r\n",
    "    model = create_model()\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,256,321\n",
      "Trainable params: 4,256,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,256,321\n",
      "Trainable params: 4,256,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5REiP_a-XhPy",
    "outputId": "15dfc149-29ed-474b-9dec-331c03ba1b35"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "\r\n",
    "\r\n",
    "history = model.fit_generator(\r\n",
    "  train,\r\n",
    "  steps_per_epoch = 3600//18,\r\n",
    "  epochs = 100,\r\n",
    "  verbose=1,\r\n",
    "  validation_data=test,\r\n",
    "  validation_steps=3600//18,\r\n",
    "\r\n",
    "  callbacks=callback_list\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x000001EADA1B35E0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmph7v1sk0x.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x000001EADA1B35E0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmph7v1sk0x.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "200/200 [==============================] - 91s 371ms/step - loss: 0.6414 - accuracy: 0.6230 - val_loss: 0.4378 - val_accuracy: 0.7965\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79654, saving model to Datasets\\best_model.hdf5\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 70s 353ms/step - loss: 0.4823 - accuracy: 0.7652 - val_loss: 0.3738 - val_accuracy: 0.8544\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.79654 to 0.85444, saving model to Datasets\\best_model.hdf5\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 70s 350ms/step - loss: 0.4102 - accuracy: 0.8027 - val_loss: 0.4071 - val_accuracy: 0.8259\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.85444\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 69s 346ms/step - loss: 0.3745 - accuracy: 0.8404 - val_loss: 0.2639 - val_accuracy: 0.8964\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.85444 to 0.89642, saving model to Datasets\\best_model.hdf5\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 69s 345ms/step - loss: 0.3172 - accuracy: 0.8568 - val_loss: 0.2110 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.89642 to 0.92765, saving model to Datasets\\best_model.hdf5\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 0.2971 - accuracy: 0.8796 - val_loss: 0.2453 - val_accuracy: 0.9058\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.92765\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 70s 349ms/step - loss: 0.2572 - accuracy: 0.8978 - val_loss: 0.1775 - val_accuracy: 0.9340\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.92765 to 0.93396, saving model to Datasets\\best_model.hdf5\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 0.2401 - accuracy: 0.9043 - val_loss: 0.2158 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.93396\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 0.2058 - accuracy: 0.9205 - val_loss: 0.1254 - val_accuracy: 0.9531\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.93396 to 0.95307, saving model to Datasets\\best_model.hdf5\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 0.2029 - accuracy: 0.9207 - val_loss: 0.1379 - val_accuracy: 0.9506\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.95307\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 0.1829 - accuracy: 0.9294 - val_loss: 0.1846 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.95307\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 69s 347ms/step - loss: 0.1787 - accuracy: 0.9322 - val_loss: 0.1254 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.95307 to 0.95904, saving model to Datasets\\best_model.hdf5\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "jDB1vR370bii",
    "outputId": "267e99d2-b7e4-4dd6-b72a-a401bdc844e9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "model.save(\"model.h5\")"
   ],
   "outputs": [],
   "metadata": {
    "id": "d458UFun0TGn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "best_model = tf.keras.models.load_model(\"Datasets/best_model.hdf5\")\r\n",
    "model = tf.keras.models.load_model(\"model.h5\")"
   ],
   "outputs": [],
   "metadata": {
    "id": "Sqri6T96yS5v"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "[model_loss,model_accuracy] = model.evaluate_generator(test,verbose=1)\r\n",
    "[best_model_loss,best_model_accuracy] = best_model.evaluate_generator(test,verbose=1)\r\n",
    "if model_accuracy>best_model_accuracy:\r\n",
    "    model.save(\"Datasets/model.h5\")\r\n",
    "    print(\"Saved New Model\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42/42 [==============================] - 3s 58ms/step - loss: 0.1240 - accuracy: 0.9594\n",
      "42/42 [==============================] - 3s 59ms/step - loss: 0.1240 - accuracy: 0.9594\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JMS1IgFycL8",
    "outputId": "953ae917-e068-45c9-df20-93046c166f61"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "id": "eOEGKzxdzO9l"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "history_visible": true,
   "machine_shape": "hm",
   "name": "Copy of CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}